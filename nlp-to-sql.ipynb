{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language to SQL Proof of Concept\n",
    "\n",
    "A simple proof of concept that allows a non-programmer to write a program in natural language and have it converted to SQL Code.\n",
    "\n",
    "#### What is natural language?\n",
    "A natural language, as described when [Dictionary.com](https://www.dictionary.com/browse/natural-language) states, \"a language that has developed and evolved naturally, through use by human beings, as opposed to an invented or constructed language, as a computer programming language\". Simply put, a natural language is a language that is used by humans to communicate with each other. The setences that you are reading right now are written in natural language.\n",
    "\n",
    "#### What is SQL?\n",
    "SQL, or Structured Query Language, is a \"Structured Query Language (SQL) is a standardized programming language that is used to manage relational databases and perform various operations on the data in them\" [Techtarget.com](https://www.techtarget.com/searchdatamanagement/definition/SQL#:~:text=Structured%20Query%20Language%20(SQL)%20is,on%20the%20data%20in%20them.).\n",
    "\n",
    "#### The difference between natural language and SQL\n",
    "Natural language is used to communicate with other humans. SQL is used to communicate with a database. The two languages are very different. For example, in natural language, you can say:\n",
    "    \n",
    "    \"I want to buy a car, but my budget is no more than $10000\"\n",
    "\n",
    "In SQL, you would say:\n",
    "\n",
    "    \"SELECT * FROM cars WHERE price < 10000\"\n",
    "    \n",
    "The two sentences are very different, but they both mean the same thing. An engineer who understands both the natural language and SQL can easily convert the two back and forward. If a non-technical tells them they need a report for all sales within the last 30 days, the engineer can easily convert that to SQL and get the data. \n",
    "\n",
    "What we want to do is show that not only can an engineer do it, but GPT can as well.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Imports\n",
    "\n",
    "We will need a number of different python libraries to make this work. We will need to import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installed Package Imports\n",
    "import pandas as pd\n",
    "import openai\n",
    "import dotenv\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Imports\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Safeguarding our API Key\n",
    "\n",
    "We can easily obfuscate the API Key that we are using by storing it in a environment variables file, or a .env file. We can then import the .env file into our notebook and use the API Key without having to worry about it being exposed.\n",
    "\n",
    "The .env will have an entry that looks like this:\n",
    "\n",
    "OPENAI=Our-API-Key-is-Stored-Here\n",
    "\n",
    "This is imported using a package called Dotenv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key is Stored in a .env File, please see the .env.example file for more information\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAPI\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration\n",
    "\n",
    "First we must import and explore our data just to get an idea of what we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the sample data \n",
    "df = pd.read_csv(\"data/sales_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDERNUMBER</th>\n",
       "      <th>QUANTITYORDERED</th>\n",
       "      <th>PRICEEACH</th>\n",
       "      <th>ORDERLINENUMBER</th>\n",
       "      <th>SALES</th>\n",
       "      <th>ORDERDATE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>QTR_ID</th>\n",
       "      <th>MONTH_ID</th>\n",
       "      <th>YEAR_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>ADDRESSLINE1</th>\n",
       "      <th>ADDRESSLINE2</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>POSTALCODE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>TERRITORY</th>\n",
       "      <th>CONTACTLASTNAME</th>\n",
       "      <th>CONTACTFIRSTNAME</th>\n",
       "      <th>DEALSIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10107</td>\n",
       "      <td>30</td>\n",
       "      <td>95.70</td>\n",
       "      <td>2</td>\n",
       "      <td>2871.00</td>\n",
       "      <td>2/24/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>897 Long Airport Avenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>10022</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yu</td>\n",
       "      <td>Kwai</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10121</td>\n",
       "      <td>34</td>\n",
       "      <td>81.35</td>\n",
       "      <td>5</td>\n",
       "      <td>2765.90</td>\n",
       "      <td>5/7/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>59 rue de l'Abbaye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reims</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51100</td>\n",
       "      <td>France</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Henriot</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10134</td>\n",
       "      <td>41</td>\n",
       "      <td>94.74</td>\n",
       "      <td>2</td>\n",
       "      <td>3884.34</td>\n",
       "      <td>7/1/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>27 rue du Colonel Pierre Avia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75508</td>\n",
       "      <td>France</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Da Cunha</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10145</td>\n",
       "      <td>45</td>\n",
       "      <td>83.26</td>\n",
       "      <td>6</td>\n",
       "      <td>3746.70</td>\n",
       "      <td>8/25/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>78934 Hillside Dr.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>90003</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10159</td>\n",
       "      <td>49</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14</td>\n",
       "      <td>5205.27</td>\n",
       "      <td>10/10/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>7734 Strong St.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
       "0        10107               30      95.70                2  2871.00   \n",
       "1        10121               34      81.35                5  2765.90   \n",
       "2        10134               41      94.74                2  3884.34   \n",
       "3        10145               45      83.26                6  3746.70   \n",
       "4        10159               49     100.00               14  5205.27   \n",
       "\n",
       "         ORDERDATE   STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
       "0   2/24/2003 0:00  Shipped       1         2     2003  ...   \n",
       "1    5/7/2003 0:00  Shipped       2         5     2003  ...   \n",
       "2    7/1/2003 0:00  Shipped       3         7     2003  ...   \n",
       "3   8/25/2003 0:00  Shipped       3         8     2003  ...   \n",
       "4  10/10/2003 0:00  Shipped       4        10     2003  ...   \n",
       "\n",
       "                    ADDRESSLINE1  ADDRESSLINE2           CITY STATE  \\\n",
       "0        897 Long Airport Avenue           NaN            NYC    NY   \n",
       "1             59 rue de l'Abbaye           NaN          Reims   NaN   \n",
       "2  27 rue du Colonel Pierre Avia           NaN          Paris   NaN   \n",
       "3             78934 Hillside Dr.           NaN       Pasadena    CA   \n",
       "4                7734 Strong St.           NaN  San Francisco    CA   \n",
       "\n",
       "  POSTALCODE COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
       "0      10022     USA       NaN              Yu             Kwai    Small  \n",
       "1      51100  France      EMEA         Henriot             Paul    Small  \n",
       "2      75508  France      EMEA        Da Cunha           Daniel   Medium  \n",
       "3      90003     USA       NaN           Young            Julie   Medium  \n",
       "4        NaN     USA       NaN           Brown            Julie   Medium  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database Setup\n",
    "\n",
    "As we want to perform SQL queries we need to store our CSV data in a database. We can do this using SQL Alchemy, using the module called create_engine. We will create a database called \"temp_db\" that is stored in memory. We then push our data into the database in a table called \"sales\".\n",
    "\n",
    "After that, we can perform queries against the database using the text module that we import from SQL Alchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are going to create a temporary database in memory\n",
    "temp_db = create_engine('sqlite:///:memory:', echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 10:27:29,486 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"sales\")\n",
      "2023-03-09 10:27:29,487 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2023-03-09 10:27:29,488 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"sales\")\n",
      "2023-03-09 10:27:29,489 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2023-03-09 10:27:29,492 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2023-03-09 10:27:29,493 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE sales (\n",
      "\t\"index\" BIGINT, \n",
      "\t\"ORDERNUMBER\" BIGINT, \n",
      "\t\"QUANTITYORDERED\" BIGINT, \n",
      "\t\"PRICEEACH\" FLOAT, \n",
      "\t\"ORDERLINENUMBER\" BIGINT, \n",
      "\t\"SALES\" FLOAT, \n",
      "\t\"ORDERDATE\" TEXT, \n",
      "\t\"STATUS\" TEXT, \n",
      "\t\"QTR_ID\" BIGINT, \n",
      "\t\"MONTH_ID\" BIGINT, \n",
      "\t\"YEAR_ID\" BIGINT, \n",
      "\t\"PRODUCTLINE\" TEXT, \n",
      "\t\"MSRP\" BIGINT, \n",
      "\t\"PRODUCTCODE\" TEXT, \n",
      "\t\"CUSTOMERNAME\" TEXT, \n",
      "\t\"PHONE\" TEXT, \n",
      "\t\"ADDRESSLINE1\" TEXT, \n",
      "\t\"ADDRESSLINE2\" TEXT, \n",
      "\t\"CITY\" TEXT, \n",
      "\t\"STATE\" TEXT, \n",
      "\t\"POSTALCODE\" TEXT, \n",
      "\t\"COUNTRY\" TEXT, \n",
      "\t\"TERRITORY\" TEXT, \n",
      "\t\"CONTACTLASTNAME\" TEXT, \n",
      "\t\"CONTACTFIRSTNAME\" TEXT, \n",
      "\t\"DEALSIZE\" TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2023-03-09 10:27:29,494 INFO sqlalchemy.engine.Engine [no key 0.00061s] ()\n",
      "2023-03-09 10:27:29,495 INFO sqlalchemy.engine.Engine CREATE INDEX ix_sales_index ON sales (\"index\")\n",
      "2023-03-09 10:27:29,496 INFO sqlalchemy.engine.Engine [no key 0.00073s] ()\n",
      "2023-03-09 10:27:29,497 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2023-03-09 10:27:29,504 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2023-03-09 10:27:29,620 INFO sqlalchemy.engine.Engine INSERT INTO sales (\"index\", \"ORDERNUMBER\", \"QUANTITYORDERED\", \"PRICEEACH\", \"ORDERLINENUMBER\", \"SALES\", \"ORDERDATE\", \"STATUS\", \"QTR_ID\", \"MONTH_ID\", \"YEAR_ID\", \"PRODUCTLINE\", \"MSRP\", \"PRODUCTCODE\", \"CUSTOMERNAME\", \"PHONE\", \"ADDRESSLINE1\", \"ADDRESSLINE2\", \"CITY\", \"STATE\", \"POSTALCODE\", \"COUNTRY\", \"TERRITORY\", \"CONTACTLASTNAME\", \"CONTACTFIRSTNAME\", \"DEALSIZE\") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2023-03-09 10:27:29,620 INFO sqlalchemy.engine.Engine [generated in 0.10523s] ((0, 10107, 30, 95.7, 2, 2871.0, '2/24/2003 0:00', 'Shipped', 1, 2, 2003, 'Motorcycles', 95, 'S10_1678', 'Land of Toys Inc.', '2125557818', '897 Long Airport Avenue', None, 'NYC', 'NY', '10022', 'USA', None, 'Yu', 'Kwai', 'Small'), (1, 10121, 34, 81.35, 5, 2765.9, '5/7/2003 0:00', 'Shipped', 2, 5, 2003, 'Motorcycles', 95, 'S10_1678', 'Reims Collectables', '26.47.1555', \"59 rue de l'Abbaye\", None, 'Reims', None, '51100', 'France', 'EMEA', 'Henriot', 'Paul', 'Small'), (2, 10134, 41, 94.74, 2, 3884.34, '7/1/2003 0:00', 'Shipped', 3, 7, 2003, 'Motorcycles', 95, 'S10_1678', 'Lyon Souveniers', '+33 1 46 62 7555', '27 rue du Colonel Pierre Avia', None, 'Paris', None, '75508', 'France', 'EMEA', 'Da Cunha', 'Daniel', 'Medium'), (3, 10145, 45, 83.26, 6, 3746.7, '8/25/2003 0:00', 'Shipped', 3, 8, 2003, 'Motorcycles', 95, 'S10_1678', 'Toys4GrownUps.com', '6265557265', '78934 Hillside Dr.', None, 'Pasadena', 'CA', '90003', 'USA', None, 'Young', 'Julie', 'Medium'), (4, 10159, 49, 100.0, 14, 5205.27, '10/10/2003 0:00', 'Shipped', 4, 10, 2003, 'Motorcycles', 95, 'S10_1678', 'Corporate Gift Ideas Co.', '6505551386', '7734 Strong St.', None, 'San Francisco', 'CA', None, 'USA', None, 'Brown', 'Julie', 'Medium'), (5, 10168, 36, 96.66, 1, 3479.76, '10/28/2003 0:00', 'Shipped', 4, 10, 2003, 'Motorcycles', 95, 'S10_1678', 'Technics Stores Inc.', '6505556809', '9408 Furth Circle', None, 'Burlingame', 'CA', '94217', 'USA', None, 'Hirano', 'Juri', 'Medium'), (6, 10180, 29, 86.13, 9, 2497.77, '11/11/2003 0:00', 'Shipped', 4, 11, 2003, 'Motorcycles', 95, 'S10_1678', 'Daedalus Designs Imports', '20.16.1555', '184, chausse de Tournai', None, 'Lille', None, '59000', 'France', 'EMEA', 'Rance', 'Martine', 'Small'), (7, 10188, 48, 100.0, 1, 5512.32, '11/18/2003 0:00', 'Shipped', 4, 11, 2003, 'Motorcycles', 95, 'S10_1678', 'Herkku Gifts', '+47 2267 3215', 'Drammen 121, PR 744 Sentrum', None, 'Bergen', None, 'N 5804', 'Norway', 'EMEA', 'Oeztan', 'Veysel', 'Medium')  ... displaying 10 of 2823 total bound parameter sets ...  (2821, 10397, 34, 62.24, 1, 2116.16, '3/28/2005 0:00', 'Shipped', 1, 3, 2005, 'Ships', 54, 'S72_3212', 'Alpha Cognac', '61.77.6555', '1 rue Alsace-Lorraine', None, 'Toulouse', None, '31000', 'France', 'EMEA', 'Roulet', 'Annette', 'Small'), (2822, 10414, 47, 65.52, 9, 3079.44, '5/6/2005 0:00', 'On Hold', 2, 5, 2005, 'Ships', 54, 'S72_3212', 'Gifts4AllAges.com', '6175559555', '8616 Spinnaker Dr.', None, 'Boston', 'MA', '51003', 'USA', None, 'Yoshido', 'Juri', 'Medium'))\n",
      "2023-03-09 10:27:29,639 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "# Now we push the Pandas DF to the database that we can perform SQL queries on. As we set echo to true, we get to see the SQL query that is being executed while creating the table\n",
    "data = df.to_sql('sales', con=temp_db, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 10:27:30,034 INFO sqlalchemy.engine.Engine SELECT * FROM sales LIMIT 5\n",
      "2023-03-09 10:27:30,035 INFO sqlalchemy.engine.Engine [generated in 0.00078s] ()\n",
      "(0, 10107, 30, 95.7, 2, 2871.0, '2/24/2003 0:00', 'Shipped', 1, 2, 2003, 'Motorcycles', 95, 'S10_1678', 'Land of Toys Inc.', '2125557818', '897 Long Airport Avenue', None, 'NYC', 'NY', '10022', 'USA', None, 'Yu', 'Kwai', 'Small')\n",
      "(1, 10121, 34, 81.35, 5, 2765.9, '5/7/2003 0:00', 'Shipped', 2, 5, 2003, 'Motorcycles', 95, 'S10_1678', 'Reims Collectables', '26.47.1555', \"59 rue de l'Abbaye\", None, 'Reims', None, '51100', 'France', 'EMEA', 'Henriot', 'Paul', 'Small')\n",
      "(2, 10134, 41, 94.74, 2, 3884.34, '7/1/2003 0:00', 'Shipped', 3, 7, 2003, 'Motorcycles', 95, 'S10_1678', 'Lyon Souveniers', '+33 1 46 62 7555', '27 rue du Colonel Pierre Avia', None, 'Paris', None, '75508', 'France', 'EMEA', 'Da Cunha', 'Daniel', 'Medium')\n",
      "(3, 10145, 45, 83.26, 6, 3746.7, '8/25/2003 0:00', 'Shipped', 3, 8, 2003, 'Motorcycles', 95, 'S10_1678', 'Toys4GrownUps.com', '6265557265', '78934 Hillside Dr.', None, 'Pasadena', 'CA', '90003', 'USA', None, 'Young', 'Julie', 'Medium')\n",
      "(4, 10159, 49, 100.0, 14, 5205.27, '10/10/2003 0:00', 'Shipped', 4, 10, 2003, 'Motorcycles', 95, 'S10_1678', 'Corporate Gift Ideas Co.', '6505551386', '7734 Strong St.', None, 'San Francisco', 'CA', None, 'USA', None, 'Brown', 'Julie', 'Medium')\n"
     ]
    }
   ],
   "source": [
    "# Now we can perform SQL queries on the data\n",
    "with temp_db.connect() as con:\n",
    "    rs = con.execute(text(\"SELECT * FROM sales LIMIT 5\"))\n",
    "    for row in rs:\n",
    "        print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP to SQL\n",
    "\n",
    "To do this we are going to create a couple of functions:\n",
    "\n",
    "1. A function that creates a table structure defintion from the DataFrame\n",
    "2. A function that grabs the user's language input.\n",
    "3. A function that combines prmops for our API call"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table Definition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_def(df):\n",
    "    prompt = \"\"\"### Sqlite SQL table, with it's properties:\n",
    "    #\n",
    "    # Sales({})\n",
    "    #\n",
    "    \"\"\".format(\",\".join(str(col) for col in df.columns))\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A breakdown of the Create Table Def Function:\n",
    "\n",
    "```\n",
    "    Sales({})\n",
    "```\n",
    "We create a table called sales, with the columns to be injected where we placed the {}\n",
    "\n",
    "```\n",
    "    .format(\",\".join(str(col) for col in df.columns))\n",
    "```\n",
    "\n",
    "We then loop through the columns in our DataFrame and add them to the table definition. We also add a comma between each column.\n",
    "\n",
    "As such we end up with the following:\n",
    "\n",
    "```\n",
    "    Sales(col1, col2, col3, col4, ...)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get User Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt():\n",
    "    user_prompt = input(\"Please enter your prompt: \")\n",
    "    return user_prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A breakdown of the User Input :\n",
    "\n",
    "This is a simple function that just promppts the user for an input, which is then returned.\n",
    "\n",
    "An example of this:\n",
    "\n",
    "```\n",
    "    prompt()\n",
    "```\n",
    "\n",
    "```\n",
    "    $ Please enter your prompt: \"I want to buy a car, but my budget is no more than $10000\"\n",
    "```\n",
    "\n",
    "What is returned as a variable:\n",
    "```\n",
    "    \"I want to buy a car, but my budget is no more than $10000\"\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of the Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts(df, user_prompt):\n",
    "    definition = create_table_def(df)\n",
    "    query_string = f\"### A query to answer: {user_prompt}\\nSELECT\"\n",
    "    return definition + query_string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of the Combination Function\n",
    "\n",
    "This function is passed two parameters, a Pandas DataFrame and a User prompt string.\n",
    "\n",
    "First it creats a table definition using the Create Table Def Function and the passed DataFrame.\n",
    "\n",
    "```\n",
    "    definition = create_table_def(df)\n",
    "```\n",
    "\n",
    "Then it creates a query string, ending in the start of the SQL query, with the passed User Prompt.\n",
    "\n",
    "```\n",
    "    query_string = f\"### A query to answer: {user_prompt}\\nSELECT\"\n",
    "```\n",
    "\n",
    "Finally, it combines the two prompts and returns them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Sqlite SQL table, with it's properties:\\n    #\\n    # Sales(ORDERNUMBER,QUANTITYORDERED,PRICEEACH,ORDERLINENUMBER,SALES,ORDERDATE,STATUS,QTR_ID,MONTH_ID,YEAR_ID,PRODUCTLINE,MSRP,PRODUCTCODE,CUSTOMERNAME,PHONE,ADDRESSLINE1,ADDRESSLINE2,CITY,STATE,POSTALCODE,COUNTRY,TERRITORY,CONTACTLASTNAME,CONTACTFIRSTNAME,DEALSIZE)\\n    #\\n    ### A query to answer: I want the total sales by year\\nSELECT\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we grab the natural language\n",
    "nlp_text = prompt()\n",
    "\n",
    "# Then we pass the data frame and the prompt to the function\n",
    "combine_prompts(df, nlp_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what is return after we run the above cell with the user input \"Grab all sales per month\". This is what we will send to GPT.\n",
    "\n",
    "        \"### Sqlite SQL table, with it's properties:\\n\n",
    "        #\\n\n",
    "        # Sales(ORDERNUMBER,QUANTITYORDERED,PRICEEACH,ORDERLINENUMBER,SALES,ORDERDATE,STATUS,QTR_ID,MONTH_ID,\n",
    "        YEAR_ID,PRODUCTLINE,MSRP,PRODUCTCODE,CUSTOMERNAME,PHONE,ADDRESSLINE1,ADDRESSLINE2,CITY,STATE,POSTALCODE,\n",
    "        COUNTRY,TERRITORY,CONTACTLASTNAME,CONTACTFIRSTNAME,DEALSIZE)\\n\n",
    "        #\\n    ### A query to answer: I want the total sales by year\\nSELECT\"\n",
    "\n",
    "The final SELECT is not actually needed, but as GPT can be thought of partially as a text completition engine, it will push it towards creating an SQL query."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT API Call\n",
    "\n",
    "Now we can pass our prompt to the GPT API. To do this, we will call the OpenAI Completion Create module that requires a few parameters:\n",
    "\n",
    "* Engine: This is the engine that we want to use. We will use the DAVINCI engine, first we will use the code specific 'code-davinci-002' and then later we will try the updated 'text-davinci-003'\n",
    "\n",
    "* Prompt: This is the prompt that we want to pass to GPT. This is the combination of the table definition and the user prompt.\n",
    "\n",
    "* Temperature: This is the temperature of the model. The higher the temperature, the more likely the model is to take a risk and generate novel, creative text. Lower temperatures result in more likely text. We will use a temperature of 0 as we do not want a random response and we are looking for something very specific\n",
    "\n",
    "* Max Tokens: This is the maximum number of tokens that the model will return. This needs to be large enough to get a full SQL Query back, but not too large that it starts to return gibberish. We will use 200.\n",
    "\n",
    "* Top P: This is the cumulative probability that will be used to truncate the distribution. We will use 1 as we want to get the most likely response.\n",
    "\n",
    "* Frequency Penalty: This is a parameter that penalizes new tokens based on their existing frequency in the text so far. This is used to encourage diversity in the response. We will use 0 as we want to get the most likely response.\n",
    "\n",
    "* Presence Penalty: This is a parameter that penalizes new tokens based on whether they appear in the text so far. This is used to encourage diversity in the response. We will use 0 as we want to get the most likely response.\n",
    "\n",
    "* Stop Sequence: This is a string that tells the model to stop generating text when it encounters the string. We will use both a '#' to stop if it starts commenting as this would mean it has finished the SQL Query, as well as a ';' as this is the end of an SQL Query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine = \"code-davinci-002\",\n",
    "    prompt = combine_prompts(df, nlp_text),\n",
    "    temperature = 0,\n",
    "    max_tokens = 200,\n",
    "    top_p = 1,\n",
    "    frequency_penalty = 0,\n",
    "    presence_penalty = 0,\n",
    "    stop = ['#', ';']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x2b111c1fd30> JSON: {\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"index\": 0,\n",
       "  \"logprobs\": null,\n",
       "  \"text\": \" YEAR_ID, SUM(SALES) AS TOTAL_SALES\\nFROM Sales\\nGROUP BY YEAR_ID\\nORDER BY YEAR_ID\"\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handing The Response\n",
    "\n",
    "The response will need to be handled, as although we passed the SELECT to kick of an SQL Query, if you look above you can see that it was not inlcuded within the response.\n",
    "\n",
    "To do this, we look for the white space at the begining of the response, and then add the SELECT to the begining of the response.\n",
    "\n",
    "If there is no quite space, we check if the response starts with a SELECT, and if it does, we return the response.\n",
    "\n",
    "Otherwise we add SELECT and a space to the start of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_response(response):\n",
    "    query = response['choices'][0]['text']\n",
    "    if query.startswith(\" \"):\n",
    "        query = \"SELECT\" + query\n",
    "    elif query.startswith(\"SELECT\"):\n",
    "        query = query\n",
    "    else:\n",
    "        query = \"SELECT \" + query\n",
    "    return query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have written the response handler, we can pass our response to it and get our SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT YEAR_ID, SUM(SALES) AS TOTAL_SALES\\nFROM Sales\\nGROUP BY YEAR_ID\\nORDER BY YEAR_ID'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_response(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our SQL Query is:\n",
    "\n",
    "    SELECT YEAR_ID, SUM(SALES) AS TOTAL_SALES\\nFROM Sales\\nGROUP BY YEAR_ID\\nORDER BY YEAR_ID\n",
    "   \n",
    "We can now run it against our database and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 10:49:18,064 INFO sqlalchemy.engine.Engine SELECT YEAR_ID, SUM(SALES) AS TOTAL_SALES\n",
      "FROM Sales\n",
      "GROUP BY YEAR_ID\n",
      "ORDER BY YEAR_ID\n",
      "2023-03-09 10:49:18,065 INFO sqlalchemy.engine.Engine [generated in 0.00113s] ()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with temp_db.connect() as con:\n",
    "    result = con.execute(text(handle_response(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2003, 3516979.540000001), (2004, 4724162.599999997), (2005, 1791486.71)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "We can see that the results are correct, and we have successfully created a NLP to SQL Query engine.\n",
    "\n",
    "We asked for total sales by year, and we got the correct SQL Query to do this.\n",
    "\n",
    "Our SQL Response was a Python list of tuples, with the year matched to it's corresponding sum of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e169bf1487165c058166e4096fcbb7435685f8d4d9486188b100d841c50245a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
